type: "DepthDetectionSubgraph"

input_stream: "input_video"
output_stream: "IMAGE:depth_image"

node {
  calculator: "FlowLimiterCalculator"
  input_stream: "input_video"
  input_stream: "FINISHED:depth_tensors"
  input_stream_info: {
    tag_index: "FINISHED"
    back_edge: true
  }
  output_stream: "throttled_input_video"
}

node: {
  calculator: "ImageTransformationCalculator"
  input_stream: "IMAGE_GPU:throttled_input_video"
  output_stream: "IMAGE_GPU:transformed_input_video_cpu"
  node_options: {
    [type.googleapis.com/mediapipe.ImageTransformationCalculatorOptions] {
      output_width: 256
      output_height: 256
      # Remove if model doesn't need to keep aspect ratio.
      # scale_mode: FILL_AND_CROP
    }
  }
}

# Converts the transformed input image on CPU into an image tensor stored as a
# TfLiteTensor.
node {
  calculator: "TfLiteConverterCalculator"
  input_stream: "IMAGE_GPU:transformed_input_video_cpu"
  output_stream: "TENSORS_GPU:image_tensor"
  options: {
    [mediapipe.TfLiteConverterCalculatorOptions.ext] {
      zero_center: true
    }
  }
}

# Use MiDaS model
# Input 256x256x3
# Output 256x256x1, not normalized
# Current speed ~ < 150ms
node {
  calculator: "TfLiteInferenceCalculator"
  input_stream: "TENSORS_GPU:image_tensor"
  output_stream: "TENSORS:depth_tensors"
  node_options: {
    [type.googleapis.com/mediapipe.TfLiteInferenceCalculatorOptions] {
      model_path: "mediapipe/models/midas_float32.tflite"
    }
  }
}

node {
  calculator: "TfLiteTensorToImageFrameCalculator"
  input_stream: "TENSORS:depth_tensors"
  output_stream: "IMAGE:depth_image"
}