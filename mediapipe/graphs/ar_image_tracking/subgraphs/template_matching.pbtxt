type: "TemplateMatchingSubgraph"

input_stream: "input_video"
output_stream: "BOXES:detections"

node {
  calculator: "PacketResamplerCalculator"
  input_stream: "DATA:input_video"
  output_stream: "DATA:throttled_input_video"
  node_options: {
    [type.googleapis.com/mediapipe.PacketResamplerCalculatorOptions] {
      frame_rate: 0.25
    }
  }
}

# Transfers the input image from GPU to CPU memory.
node: {
  calculator: "GpuBufferToImageFrameCalculator"
  input_stream: "throttled_input_video"
  output_stream: "input_video_cpu"
}

# Scale the image's longer side to 640, keeping aspect ratio.
node: {
  calculator: "ImageTransformationCalculator"
  input_stream: "IMAGE:input_video_cpu"
  output_stream: "IMAGE:transformed_input_video_cpu"
  node_options: {
    [type.googleapis.com/mediapipe.ImageTransformationCalculatorOptions] {
      output_width: 640
      output_height: 640
      scale_mode: FILL_AND_CROP
    }
  }
}

node {
  calculator: "ImagePropertiesCalculator"
  input_stream: "IMAGE:transformed_input_video_cpu"
  output_stream: "SIZE:input_video_size"
}

node {
  calculator: "FeatureDetectorCalculator"
  input_stream: "IMAGE:transformed_input_video_cpu"
  output_stream: "FEATURES:features"
  output_stream: "PATCHES:patches"
}

# input tensors: 200*32*32*1 float
# output tensors: 200*40 float, only first keypoint.size()*40 is knift features,
# rest is padded by zero.
node {
  calculator: "TfLiteInferenceCalculator"
  input_stream: "TENSORS:patches"
  output_stream: "TENSORS:knift_feature_tensors"
  node_options: {
    [type.googleapis.com/mediapipe.TfLiteInferenceCalculatorOptions] {
      model_path: "mediapipe/models/knift_float.tflite"
      delegate { xnnpack {} }
    }
  }
}

node {
  calculator: "TfLiteTensorsToFloatsCalculator"
  input_stream: "TENSORS:knift_feature_tensors"
  output_stream: "FLOATS:knift_feature_floats"
}

node {
  calculator: "BoxDetectorCalculator"
  input_stream: "FEATURES:features"
  input_stream: "IMAGE_SIZE:input_video_size"
  input_stream: "DESCRIPTORS:knift_feature_floats"
  output_stream: "BOXES:detections"

  node_options: {
    [type.googleapis.com/mediapipe.BoxDetectorCalculatorOptions] {
      detector_options {
        index_type: OPENCV_BF
        detect_every_n_frame: 1
      }
      index_proto_filename: "mediapipe/models/knift_index.pb"
    }
  }
}